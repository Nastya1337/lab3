{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3085ec43-34bb-4afb-9515-517e0489db3e",
   "metadata": {},
   "source": [
    "## Классические алгоритмы без ансамблирования\n",
    "В этом ноутбуке вам нужно обучить модели на датасете классификации из предыдущего ноутбука и сравнить результаты. Вам будет предоставлен baseline, на основе которого вы будете доделывать предсказывающие модели. Оценка лабы будет зависеть от ROC-AUC на тестовых данных по следующим критериям:\n",
    "\\\n",
    "AUC - на тестовых данных\n",
    "- $AUC \\leq 0.75$ - 0 баллов\n",
    "- $0.75 < AUC \\leq 0.76$ - 2 балла\n",
    "- $0.76 < AUC \\leq 0.77$ - 4 балла\n",
    "- $0.77 < AUC \\leq 0.78$ - 6 баллов\n",
    "- $0.78 < AUC \\leq 0.79$ - 8 баллов\n",
    "- $AUC > 0.79$ - 10 баллов\n",
    "\n",
    "\\\n",
    "В этой работе запрещено использовать ансамбли моделей (лес, бустинги и т.д.)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07e3a2-480a-4350-868e-02679ff2aada",
   "metadata": {},
   "outputs": [],
   "source": [
" from sklearn.linear_model import LogisticRegression \n",
" from sklearn.tree import DecisionTreeClassifier \n",
" from sklearn.neighbors import KNeighborsClassifier \n",
"  \n",
" from sklearn.metrics import roc_auc_score, precision_score, recall_score, roc_curve, accuracy_score \n",
" from sklearn.preprocessing import StandardScaler \n",
" from sklearn.model_selection import train_test_split \n",
"  \n",
" import matplotlib.pyplot as plt \n",
" import pandas as pd \n",
" import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ad31b-5c83-4366-819a-34dad4edecdc",
   "metadata": {},
   "outputs": [],
   "source": [
" data = pd.read_csv('german.csv', sep=';') \n",
" print(data.head()) \n",
"  \n",
" X = data.iloc[:, 1:].to_numpy() \n",
" y = data.iloc[:, 0].to_numpy() \n",
"  \n",
" scaler = StandardScaler() \n",
" X_scaled = scaler.fit_transform(X) \n",
"  \n",
" X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n"
   ]
  },
  {
"cell_type": "code",
   "execution_count": null,
   "id": "1ccf0690-1d07-4026-85f2-674c5688d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
" models = { \n",
"     'Logistic Regression': LogisticRegression(max_iter=1000, C=1.0, solver='liblinear'), \n",
"     'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=5, min_samples_split=10), \n",
"     'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, weights='uniform') \n",
" } \n",
"  \n",
" for model_name, model in models.items(): \n",
"     model.fit(X_train, y_train) \n",
"     y_prob = model.predict_proba(X_test)[:, 1] \n",
"     auc_score = roc_auc_score(y_test, y_prob) \n",
"     print(f'{model_name} AUC: {auc_score:.4f}') \n",
"  \n",
" plt.figure(figsize=(10, 8)) \n",
" for model_name, model in models.items(): \n",
"     y_prob = model.predict_proba(X_test)[:, 1] \n",
"     fpr, tpr, _ = roc_curve(y_test, y_prob) \n",
"     plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc_score(y_test, y_prob):.2f})') \n",
"  \n",
" plt.hist(y_train, bins=2, edgecolor='k') \n",
" plt.xticks([0, 1]) \n",
" plt.xlabel('Class (0: Non-Creditworthy, 1: Creditworthy)') \n",
" plt.ylabel('Count') \n",
" plt.title('Distribution of Classes in Training Data') \n",
" plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf0690-1d07-4026-85f2-674c5688d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
" logistic_regression_model = LogisticRegression(max_iter=1000) \n",
" logistic_regression_model.fit(X_train, y_train) \n",
"  \n",
" decision_tree_model = DecisionTreeClassifier(random_state=42) \n",
" decision_tree_model.fit(X_train, y_train) \n",
"  \n",
" knn_model = KNeighborsClassifier(n_neighbors=5) \n",
" knn_model.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ebd8b0-3f81-4365-9f84-44bf50bbcbe4",
   "metadata": {},
   "outputs": [],
   "source": [
" y_prob_logistic = logistic_regression_model.predict_proba(X_test)[:, 1] \n",
" y_prob_decision_tree = decision_tree_model.predict_proba(X_test)[:, 1] \n",
" y_prob_knn = knn_model.predict_proba(X_test)[:, 1] \n",
"  \n",
" y_pred_logistic = logistic_regression_model.predict(X_test) \n",
" y_pred_decision_tree = decision_tree_model.predict(X_test) \n",
" y_pred_knn = knn_model.predict(X_test) \n",
"  \n",
" accuracy_logistic = accuracy_score(y_test, y_pred_logistic) \n",
" accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree) \n",
" accuracy_knn = accuracy_score(y_test, y_pred_knn) \n",
"  \n",
" roc_auc_logistic = roc_auc_score(y_test, y_prob_logistic) \n",
" roc_auc_decision_tree = roc_auc_score(y_test, y_prob_decision_tree) \n",
" roc_auc_knn = roc_auc_score(y_test, y_prob_knn) \n",
"  \n",
" precision_logistic = precision_score(y_test, y_pred_logistic) \n",
" precision_decision_tree = precision_score(y_test, y_pred_decision_tree) \n",
" precision_knn = precision_score(y_test, y_pred_knn) \n",
"  \n",
" recall_logistic = recall_score(y_test, y_pred_logistic) \n",
" recall_decision_tree = recall_score(y_test, y_pred_decision_tree) \n",
" recall_knn = recall_score(y_test, y_pred_knn) \n",
"  \n",
" print(f'Accuracy of Logistic Regression: {accuracy_logistic}') \n",
" print(f'Accuracy of Decision Tree: {accuracy_decision_tree}') \n",
" print(f'Accuracy of K-Nearest Neighbors: {accuracy_knn}') \n",
"  \n",
" print(f'ROC AUC of Logistic Regression: {roc_auc_logistic}') \n",
" print(f'ROC AUC of Decision Tree: {roc_auc_decision_tree}') \n",
" print(f'ROC AUC of K-Nearest Neighbors: {roc_auc_knn}') \n",
"  \n",
" print(f'Precision of Logistic Regression: {precision_logistic}') \n",
" print(f'Precision of Decision Tree: {precision_decision_tree}') \n",
" print(f'Precision of K-Nearest Neighbors: {precision_knn}') \n",
"  \n",
" print(f'Recall of Logistic Regression: {recall_logistic}') \n",
" print(f'Recall of Decision Tree: {recall_decision_tree}') \n",
" print(f'Recall of K-Nearest Neighbors: {recall_knn}') \n",
" # У нас AUC > 0.79, он равен: 0.7903\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6eb00-77fd-40dc-a3c5-35c1fe0200c0",
   "metadata": {},
   "source": [
    "## Экспериментируйте\n",
    "Для получения лучшего качества придется поэкспериментировать. Подсказка: попробуйте оптимизировать гиперпараметры модели",
"## Вывод \n",
"    Creditability  Account_Balance  Duration_of_Credit_monthly  Payment_Status_of_Previous_Credit  ...  Occupation  No_of_dependents  Telephone  Foreign_Worker \n",
" 0              1                1                          18                                  4  ...           3                 1          1               1 \n",
" 1              1                1                           9                                  4  ...           3                 2          1               1 \n",
" 2              1                2                          12                                  2  ...           2                 1          1               1 \n",
" 3              1                1                          12                                  4  ...           2                 2          1               2 \n",
" 4              1                1                          12                                  4  ...           2                 1          1               2 \n",
"  \n",
" [5 rows x 21 columns] \n",
" Logistic Regression AUC: 0.7903         ###############   AUC > 0.79  \n",
" Decision Tree AUC: 0.7062 \n",
" K-Nearest Neighbors AUC: 0.5782 \n",
" C:\Users\grifk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1): \n",
" STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. \n",
"  \n",
" Increase the number of iterations (max_iter) or scale the data as shown in: \n",
"     https://scikit-learn.org/stable/modules/preprocessing.html \n",
"     https://scikit-learn.org/stable/modules/preprocessing.html \n",
" Please also refer to the documentation for alternative solver options: \n",
"     https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression \n",
" Please also refer to the documentation for alternative solver options: \n",
"     https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression \n",
"   n_iter_i = _check_optimize_result( \n",
"   n_iter_i = _check_optimize_result( \n",
" Accuracy of Logistic Regression: 0.745 \n",
" Accuracy of Logistic Regression: 0.745 \n",
" Accuracy of Decision Tree: 0.725 \n",
" Accuracy of Decision Tree: 0.725 \n",
" Accuracy of K-Nearest Neighbors: 0.66 \n",
" Accuracy of K-Nearest Neighbors: 0.66 \n",
" ROC AUC of Logistic Regression: 0.7932445067788686 \n",
" ROC AUC of Logistic Regression: 0.7932445067788686 \n",
" ROC AUC of Decision Tree: 0.7074567554932212 \n",
" ROC AUC of K-Nearest Neighbors: 0.5781907433380085 \n",
" Precision of Logistic Regression: 0.7701863354037267 \n",
" Precision of Decision Tree: 0.832 \n",
" Precision of K-Nearest Neighbors: 0.7011494252873564 \n",
" Recall of Logistic Regression: 0.8985507246376812 \n",
" Recall of Decision Tree: 0.7536231884057971 \n",
" Recall of K-Nearest Neighbors: 0.8840579710144928 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
